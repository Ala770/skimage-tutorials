{
 "metadata": {
  "name": "",
  "signature": "sha256:5489a308025b4ef32e895da9b75191183a3648917b9398bc9fcbefbf57a0bd9d"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Image analysis fundamentals 4: segmentation\n",
      "\n",
      "\n",
      "Segmentation is the division of an image into \"meaningful\" regions. If you've seen The Terminator, you've seen image segmentation:\n",
      "\n",
      "![Terminator vision](images/terminator-vision.png)\n",
      "\n",
      "In `scikit-image`, you can find segmentation functions in the `segmentation` package (oddly enough), with one exception: the `watershed` function is in `morphology`, because it's a bit of both. We'll use two algorithms, SLIC and watershed, and just discuss the rest, and applications of each.\n",
      "\n",
      "There are two kinds of segmentation: *contrast-based* and *boundary-based*. The first is used when the regions of the image you are trying to divide have different characteristics, such as a red flower on a green background. The second is used when you want to segment an image in which borders between objects are prominent, but objects themselves are not very distinct. For example, a pile of oranges.\n",
      "\n",
      "## Image types: contrast\n",
      "\n",
      "SLIC is a segmentation algorithm of the first kind: it's clustering pixels in both space and color. (Simple Linear Iterative Clustering.) Therefore, regions of space that are similar in color will end up in the same segment.\n",
      "\n",
      "Let's try to segment this image:\n",
      "\n",
      "![Spice, by Clyde\n",
      "Robinson](https://farm6.staticflickr.com/5252/5519129659_02be0e5011_o_d.jpg)\n",
      "\n",
      "(Photo by Flickr user Clyde Robinson, used under CC-BY 2.0 license.)\n",
      "\n",
      "The SLIC function takes two parameters: the desired number of segments, and the \"compactness\", which is the relative weighting of the space and color dimensions. The higher the compactness, the more \"square\" the returned segments."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "%matplotlib inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import skdemo\n",
      "from skimage import io, segmentation as seg, color\n",
      "url = 'https://farm6.staticflickr.com/5252/5519129659_02be0e5011_o_d.jpg'\n",
      "image = io.imread(url)\n",
      "labels = seg.slic(image, n_segments=18, compactness=10)\n",
      "skdemo.imshow_all(image, labels)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can try to create a nicer visualization for `labels`: each segment will be represented by its average color."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def mean_color(image, labels):\n",
      "    out = np.zeros_like(image)\n",
      "    for label in np.unique(labels):\n",
      "        indices = np.nonzero(labels == label)\n",
      "        out[indices] = np.mean(image[indices], axis=0)\n",
      "    return out\n",
      "\n",
      "skdemo.imshow_all(image, mean_color(image, labels))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Notice that some spices are broken up into \"light\" and \"dark\" parts. We have multiple parameters to control this:\n",
      "\n",
      "- `enforce_connectivity`: Do some post-processing so that small regions get merged to adjacent big regions."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "labels = seg.slic(image, n_segments=18, compactness=10,\n",
      "                  enforce_connectivity=True)\n",
      "label_image = mean_color(image, labels)\n",
      "skdemo.imshow_all(image, label_image)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Yikes! It looks like a little too much merging went on! This is because of the intertwining of the labels. One way to avoid this is to blur the image before segmentation. Because this is so useful, a Gaussian blur is included in SLIC: just pass in the `sigma` parameter:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "labels = seg.slic(image, n_segments=18, compactness=10,\n",
      "                  sigma=2, enforce_connectivity=True)\n",
      "label_image = mean_color(image, labels)\n",
      "skdemo.imshow_all(image, label_image)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Getting there! But it looks like some regions are merged together. We can alleviate this by increasing the number of segments:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "labels = seg.slic(image, n_segments=24, compactness=10,\n",
      "                  sigma=2, enforce_connectivity=True)\n",
      "label_image = mean_color(image, labels)\n",
      "skdemo.imshow_all(image, label_image)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "That's looking pretty good! Some regions are still too squiggly though... Let's try jacking up the compactness:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "labels = seg.slic(image, n_segments=24, compactness=40,\n",
      "                  sigma=2, enforce_connectivity=True)\n",
      "label_image = mean_color(image, labels)\n",
      "skdemo.imshow_all(image, label_image)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Exercise**: Write an interactive tool to explore the SLIC parameter space. Recall that the function signature is as follows:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def func(slider_kwarg, dropdown_kwarg):\n",
      "    s = some_func(image, arg1=slider_kwarg, arg2=dropdown_kwarg)\n",
      "    skdemo.imshow_all(image, s)\n",
      "from IPython import widgets\n",
      "widgets.interact(func, slider_kwarg=(start, stop, step),\n",
      "                 dropdown_kwarg=['option0', 'option1', 'option2'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Exercise**: Try segmenting the following image with a modification to the same tool:\n",
      "\n",
      "![Spices](https://farm4.staticflickr.com/3557/3326786046_8647d993db_b_d.jpg)\n",
      "\n",
      "\"Spices\" photo by Flickr user Riyaad Minty.\n",
      "https://www.flickr.com/photos/riym/3326786046\n",
      "Used under the Creative Commons CC-BY 2.0 license.\n",
      "\n",
      "Note: this image is more challenging to segment because the color regions are different from one part of the image to the other. Try the `slic_zero` parameter in combination with different values for `n_segments`."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Image types: boundary images\n",
      "\n",
      "Often, the contrast between regions is not sufficient to distinguish them, but there is a clear boundary between the two. Using an edge detector on these images, followed by a *watershed*, often gives very good segmentation. For example, look at the output of the Sobel filter on the coins image:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from skimage import data, filter as filters\n",
      "from matplotlib import pyplot as plt, cm\n",
      "coins = data.coins()\n",
      "edges = filters.sobel(coins)\n",
      "plt.imshow(edges, cmap=cm.cubehelix)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The *watershed algorithm* finds the regions between these edges. It does so by envisioning the pixel intensity as height on a topographic map. It then \"floods\" the map from the bottom up, starting from seed points. These flood areas are called \"watershed basins\" and when they meet, they form the image segmentation.\n",
      "\n",
      "Let's look at a one-dimensional example:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from skimage.morphology import watershed\n",
      "image = np.array([[1, 0, 1, 2, 1, 3, 2, 0, 2, 4, 1, 0]])\n",
      "seeds = nd.label(image == 0)[0]\n",
      "plt.plot(image[0])\n",
      "plt.plot(watershed(image, seeds)[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's find some seeds for `coins`:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from scipy import ndimage as nd\n",
      "threshold = 0.4\n",
      "distance_from_edge = nd.distance_transform_edt(edges < threshold)\n",
      "from skimage import features\n",
      "peaks = features.peak_local_max(distance_from_edge)\n",
      "seeds, num_seeds = nd.label(peaks)\n",
      "ws = watershed(edges, seeds)\n",
      "from skimage import color\n",
      "plt.imshow(color.label2rgb(ws, coins))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Exercise**: We can see that watershed gives a very good segmentation, but some coins are missing. Why? Can you suggest better seed points for the watershed operation?"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}