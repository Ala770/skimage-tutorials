{
 "metadata": {
  "celltoolbar": "Slideshow",
  "name": "",
  "signature": "sha256:268b8ae4f6dc8d62091fdd9083fccb512f371c9e29b1ceaaa7abc4afeb58348c"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Image filtering"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Image filtering theory"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Filtering is one of the most basic and common image operations in image processing. You can filter an image to remove noise or to enhance features; the filtered image could be the desired result or just a preprocessing step. Regardless, filtering is an important topic to understand."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Local filtering"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Let's get started by setting the colormap to grayscale, as discussed in the previous section."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import matplotlib.pyplot as plt\n",
      "plt.rcParams['image.cmap'] = 'gray'"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "The \"local\" in local filtering simply means that a pixel is adjusted by values in some surrounding neighborhood. These surrounding elements are identified or weighted based on a \"footprint\", \"structuring element\", or \"kernel\".\n",
      "\n",
      "Let's start with an incredibly simple image:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "\n",
      "bright_square = np.zeros((7, 7), dtype=float)\n",
      "bright_square[2:5, 2:5] = 1"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print bright_square"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.imshow(bright_square);"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "The mean filter"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "For our first example of a filter, consider the following array, which we'll call a \"mean kernel\":"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mean_kernel = 1.0/9.0 * np.ones((3, 3))\n",
      "\n",
      "print mean_kernel"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Now, lets take our mean kernel and apply it to every pixel of the image."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Applying a (linear) filter essentially means:\n",
      "* Center a kernel on a pixel\n",
      "* Multiply the pixels *under* that kernel by the values *in* the kernel\n",
      "* Sum all the those results\n",
      "* Replace the center pixel with the summed result"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "This process is known as convolution."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import skdemo\n",
      "skdemo.mean_filter_interactive_demo(bright_square)"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Let's take a look at the numerical result:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from scipy.ndimage import convolve\n",
      "\n",
      "np.set_printoptions(precision=3)\n",
      "print convolve(bright_square, mean_kernel)"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "The meaning of \"mean kernel\" should be clear now: Each pixel was replaced with the mean value within the 3x3 neighborhood of that pixel. Any time the kernel was over the bright pixel, the pixel in the kernel's center was changed to 1/9 (= 0.111). (There's only 1 non-zero pixel, so that's the maximum sum.) Anywhere else, the result was 0."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "This filter produced two important results:\n",
      "1. The intensity of the bright pixel decreased.\n",
      "2. The intensity of the region near the bright pixel increased."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Slight aside:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print mean_kernel.sum()"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Note that all the values of the kernel sum to 1. Why might that be important?"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Downsampled image"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Let's consider a real image now. It'll be easier to see some of the filtering we're doing if downsample the image a bit. We can slice into the image using the \"step\" argument to sub-sample it:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from skimage import data\n",
      "\n",
      "image = data.camera()\n",
      "pixelated = image[::10, ::10]\n",
      "skdemo.imshow_all(image, pixelated)"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Here we use a step of 10, giving us every 10 columns and every 10 rows of the original image. You can see the highly pixelated result on the right."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Mean filter on a real image"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Now we can apply the filter to this downsampled image:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "filtered = convolve(pixelated, mean_kernel)\n",
      "skdemo.imshow_all(pixelated, filtered)"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Comparing the filtered image to the pixelated image, we can see that this filtered result is smoother: Sharp edges (which are just borders between dark and bright pixels) are smoothed because dark pixels reduce the intensity of neighboring pixels and bright pixels do the opposite."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Essential filters"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "If you read through the last section, you're already familiar with the essential concepts of image filtering. But, of course, you don't have to create custom filter kernels for all of your filtering needs.\n"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Gaussian filter"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "The classic image filter is the Gaussian filter. This is similar to the mean filter, in that it tends to smooth images. The Gaussian filter, however, doesn't weight all values in the neighborhood equally. Instead, pixels closer to the center are weighted more than those farther away."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from skimage import filter\n",
      "\n",
      "sigma = 1\n",
      "smooth = filter.gaussian_filter(bright_square, sigma)\n",
      "skdemo.imshow_all(bright_square, smooth)"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "For a real image, we get the following:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from skimage import img_as_float\n",
      "# The Gaussian filter returns a float image, regardless of input.\n",
      "# Cast to float so the images have comparabale intensity ranges.\n",
      "pixelated_float = img_as_float(pixelated)\n",
      "smooth = filter.gaussian_filter(pixelated_float, 1)\n",
      "skdemo.imshow_all(pixelated_float, smooth)"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "This doesn't look drastically different than the mean filter, but the Gaussian filter is typically preferred because of the distance-dependent weighting. For a more detailed image and a larger filter, you can see artifacts in the mean filter since it doesn't take distance into account:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "size = 20\n",
      "structuring_element = np.ones((2*size + 1, 2*size + 1))\n",
      "smooth_mean = filter.rank.mean(image, structuring_element)\n",
      "smooth_gaussian = filter.gaussian_filter(image, size)\n",
      "titles = ['mean', 'gaussian']\n",
      "skdemo.imshow_all(smooth_mean, smooth_gaussian, titles=titles)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Basic edge filtering"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "A 1D difference filter"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Let's first consider an 1D edge, which is just the boundary in a step function:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "step = np.zeros(40)\n",
      "step[20:] = 1"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.plot(step, 'k')\n",
      "plt.margins(0.1) "
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "We can use convolution or cross-correlation to take a difference of neighboring values:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "edge = np.correlate(step, np.array([-1, 1]))"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.plot(step, 'k:', edge, 'r')\n",
      "plt.margins(0.1)"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Whenever neighboring values are equal, the filter response is 0. Right at the boundary of a step, we're subtracing a large value from a small value and and get a spike in the response. This spike \"identifies\" our edge."
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Difference filters in 2D"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "For images, you can think of an edge as points where the gradient is large in one direction. We can approximate gradients with difference filters. There are many ways to compute intensity differences between neighboring pixels (by weighting neighbors differently). At its simplest, you can just subtract one neighbor from the other."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "horizontal_edges = pixelated[1:, :] - pixelated[:-1, :]\n",
      "vertical_edges = pixelated[:, 1:] - pixelated[:, :-1]"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "This is exactly like the convolution filter we used in 1D, but using slicing operations instead of a filtering kernel. You'll be developing the filtering kernel in an exercise soon enough."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "skdemo.imshow_all(horizontal_edges, vertical_edges)"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "That's obviously not what we were hoping for: It all looks like noise. What's wrong here?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "In addition to the more obvious issues above, this operation has two additional issues, which can be seen below:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "horizontal_edges = bright_square[1:, :-1] - bright_square[:-1, :-1]\n",
      "vertical_edges = bright_square[:-1, 1:] - bright_square[:-1, :-1]\n",
      "skdemo.imshow_all(horizontal_edges, vertical_edges)"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print bright_square.shape, horizontal_edges.shape"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Note here that:\n",
      "1. The shape of the image isn't preserved\n",
      "2. The operation skews edges to one corner of the image.\n",
      "\n",
      "This difference operation gives the gradient *in-between* pixels, but we typically want the gradient at the same pixels as the original image."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "<span style=\"color:cornflowerblue\">Exercise:</span>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Create a simple difference filter to **find the horizontal or vertical edges** of an image. Try to ensure that the filtering operation doesn't shift the edge position preferentially."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "This should get you started:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Replace the kernels below with your difference filter\n",
      "# `ones` is used just for demonstration and your kernel should be larger than (1, 1)\n",
      "horizontal_edge_kernel = np.ones((1, 1))\n",
      "vertical_edge_kernel = np.ones((1, 1))\n",
      "\n",
      "# As discussed earlier, you may want to replace pixelated with a different image.\n",
      "image = pixelated\n",
      "horizontal_edges = convolve(image, horizontal_edge_kernel)\n",
      "vertical_edges = convolve(image, vertical_edge_kernel)\n",
      "skdemo.imshow_all(horizontal_edges, vertical_edges)"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Sobel edge filter"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "The standard Sobel filter gives the gradient magnitude. This is similar to what we saw above, except that horizontal and vertical components are combined such that the direction of the gradient is ignored.\n",
      "\n",
      "To address the issues described above, the Sobel kernel will produce a strong response if values above the center are very different than those below the center. In contrast, if the values above the center pixel are exactly equal to those below it, then responses exactly cancel each other and  this kernel replaces the center pixel with a 0."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "http://scikit-image.org/docs/dev/api/skimage.filter.html#vsobel\n",
      "http://scikit-image.org/docs/dev/api/skimage.filter.html#hsobel"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "skdemo.imshow_all(bright_square, filter.sobel(bright_square))"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Like any derivative, noise can have a strong impact on the result:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pixelated_edges = filter.sobel(pixelated)\n",
      "skdemo.imshow_all(pixelated, pixelated_edges)"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Smoothing is often used as a preprocessing step in preparation for feature detection and image-enhancement operations because sharp features can distort results."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "edges = filter.sobel(smooth)\n",
      "titles = ['edges before smoothing', 'edges after smoothing']\n",
      "skdemo.imshow_all(pixelated_edges, edges, titles=titles)"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Notice how the legs of the tripod shows up as a series of rings before smoothing, while the smoothed input produces legs that are much more linear."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "<span style=\"color:cornflowerblue\">Exercise:</span>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Using a couple of the filters in the `filter` module, **find the direction of the maximum gradient** in an image."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Denoising filters"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "This is a bit arbitrary, but here, we distinguish smoothing filters from denoising filters. We'll label denoising filters as those that are edge preserving.\n",
      "\n",
      "As you can see from our earlier examples, mean and Gaussian filters smooth an image rather uniformly, including the edges of objects in an image. When denoising, however, you typically want to preserve features and just remove noise. The distinction between noise and features can, of course, be highly situation dependent and subjective."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Median Filter"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "The median filter is the classic edge-preserving filter. As the name implies, this filter takes a set of pixels and returns a median value. Because regions near a sharp edge will have many dark values and many light values, but few values in between, the median at an edge will be either light or dark---not some value in between. In that way, we don't end up with edges that are smoothed."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from skimage.morphology import disk\n",
      "selem = disk(2)  # \"selem\" is often the name used for \"structuring element\"\n",
      "denoised = filter.rank.median(pixelated, selem)\n",
      "titles = ['image', 'gaussian', 'median']\n",
      "skdemo.imshow_all(pixelated, smooth, denoised, titles=titles)"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "This difference is more noticeable with a more detailed image."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "selem = disk(10)\n",
      "image = data.coins()\n",
      "smooth = filter.rank.mean(image, selem)\n",
      "median = filter.rank.median(image, selem)\n",
      "titles = ['image', 'mean', 'median']\n",
      "skdemo.imshow_all(image, smooth, median, titles=titles)"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Further reading"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "`scikit-image` also provides more sophisticated denoising filters:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from skimage.restoration import denoise_tv_bregman\n",
      "denoised = denoise_tv_bregman(image, 4)\n",
      "titles = ['image', 'median', 'denoised']\n",
      "skdemo.imshow_all(image, median, denoised, titles=titles)"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "* [Denoising examples](http://scikit-image.org/docs/dev/auto_examples/plot_denoise.html)\n",
      "* [Rank filters example](http://scikit-image.org/docs/dev/auto_examples/applications/plot_rank_filters.html)"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}